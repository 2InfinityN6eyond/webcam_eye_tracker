{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "DATA_ROOT_PATH = \"../eye_tracker_auto_labeller/data\"\n",
    "\n",
    "FACE_OVAL_LANDMARK_IDX_LIST = [\n",
    "    162,  21,  54, 103,  67, 109,  10, 338, 297, 332, 284, 251, 389,\n",
    "    356, 454, 323, 361, 288, 397, 365, 379, 378, 400, 377, 152, 148,\n",
    "    176, 149, 150, 136, 172,  58, 132,  93, 234, 127, 162,\n",
    "]\n",
    "LEFT_EYE_LANDMARK_IDX_LIST = [\n",
    "    263, 249, 390, 373, 374, 380, 381, 382, 362, \n",
    "    398, 384, 385, 386, 387, 388, 466, 263\n",
    "]\n",
    "LEFT_IRIS_LANDMARK_IDX_LIST = [475, 476, 477, 474, 475]\n",
    "RIGHT_EYE_LANDMARK_IDX_LIST = [\n",
    "     33,   7, 163, 144, 145, 153, 154, 155, 133,\n",
    "    173, 157, 158, 159, 160, 161, 246, 33\n",
    "]\n",
    "RIGHT_IRIS_LANDMARK_IDX_LIST = [471, 472, 469, 470, 471]\n",
    "\n",
    "OVAL_UPPER_HALF = [361, 288, 397, 365, 379, 378, 400, 377, 152, 148, 176, 149, 150, 136, 172,  58, 132]\n",
    "OVAL_LOWER_HALF = [234, 127, 162,  21,  54, 103,  67, 109,  10, 338, 297, 332, 284, 251, 389, 356, 454]\n",
    "OVAL_LEFT_HALF =  [338, 297, 332, 284, 251, 389, 356, 454, 323, 361, 288, 397, 365, 379, 378, 400, 377]\n",
    "OVAL_RIGHT_HALF = [148, 176, 149, 150, 136, 172,  58, 132,  93, 234, 127, 162,  21,  54, 103,  67, 109]\n",
    "\n",
    "class EyeTrackerDataset(Dataset) :\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_root_path = DATA_ROOT_PATH,\n",
    "        face_oval_landmark_idx_list     = FACE_OVAL_LANDMARK_IDX_LIST,\n",
    "        left_eye_landmark_idx_list      = LEFT_EYE_LANDMARK_IDX_LIST,\n",
    "        left_iris_landmark_idx_list     = LEFT_IRIS_LANDMARK_IDX_LIST,\n",
    "        right_eye_landmark_idx_list     = RIGHT_EYE_LANDMARK_IDX_LIST,\n",
    "        right_iris_landmark_idx_list    = RIGHT_IRIS_LANDMARK_IDX_LIST,\n",
    "        return_landmark = True,\n",
    "        return_image = False\n",
    "    ) :\n",
    "        super(EyeTrackerDataset, self).__init__()\n",
    "        self.DATA_ROOT_PATH = data_root_path\n",
    "        self.face_oval_landmark_idx_list    = face_oval_landmark_idx_list\n",
    "        self.left_eye_landmark_idx_list     = left_eye_landmark_idx_list\n",
    "        self.left_iris_landmark_idx_list    = left_iris_landmark_idx_list\n",
    "        self.right_eye_landmark_idx_list    = right_eye_landmark_idx_list\n",
    "        self.right_iris_landmark_idx_list   = right_iris_landmark_idx_list\n",
    "        self.return_landmark = return_landmark\n",
    "        self.return_image = return_image\n",
    "\n",
    "        self.label_path_list = sorted(glob(\n",
    "            f\"{self.DATA_ROOT_PATH}/*/*.json\"\n",
    "        ))\n",
    "        self.image_path_list = sorted(glob(\n",
    "            f\"{self.DATA_ROOT_PATH}/*/*.png\"\n",
    "        ))\n",
    "\n",
    "        # there might exists case where eiter image or label does not exist\n",
    "        # ex) a.json exist but a.png doesn't exist or vice-versa.\n",
    "        # filter this cases to ensure every data are image-label pair.\n",
    "        self.label_path_list = list(filter(\n",
    "            lambda file_name : file_name.replace(\"json\", \"png\") in self.image_path_list,\n",
    "            self.label_path_list\n",
    "        ))\n",
    "        self.image_path_list = list(filter(\n",
    "            lambda file_name : file_name.replace(\"png\", \"json\") in self.label_path_list,\n",
    "            self.image_path_list\n",
    "        ))\n",
    "        assert len(self.label_path_list) == len(self.image_path_list)\n",
    "\n",
    "        self.to_torch = transforms.ToTensor()\n",
    "\n",
    "    def __len__(self) :\n",
    "        return len(self.label_path_list)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        with open(self.label_path_list[index], \"r\") as fp :\n",
    "            label_data = json.load(fp)\n",
    "        mouse_position = torch.Tensor(label_data[\"mouse_position\"])\n",
    "        data = {\n",
    "            \"mouse_position\" : mouse_position\n",
    "        }\n",
    "        if self.return_landmark :\n",
    "            face_landmark_array = torch.Tensor(label_data[\"face_landmark_array\"])\n",
    "            face_oval_landmark_array  = face_landmark_array[self.face_oval_landmark_idx_list]\n",
    "            left_eye_landmark_array   = face_landmark_array[self.left_eye_landmark_idx_list]\n",
    "            right_eye_landmark_array  = face_landmark_array[self.right_eye_landmark_idx_list]\n",
    "            left_iris_landmark_array  = face_landmark_array[self.left_iris_landmark_idx_list]\n",
    "            right_iris_landmark_array = face_landmark_array[self.right_iris_landmark_idx_list]\n",
    "\n",
    "            data[\"face_landmark_array\"] = face_landmark_array\n",
    "            data[\"face_oval_landmark_array\"] = face_oval_landmark_array\n",
    "            data[\"left_eye_landmark_array\"] = left_eye_landmark_array\n",
    "            data[\"right_eye_landmark_array\"] = right_eye_landmark_array\n",
    "            data[\"left_iris_landmark_array\"] = left_iris_landmark_array\n",
    "            data[\"right_iris_landmark_array\"] = right_iris_landmark_array\n",
    "            data[\"face_oval_mean\"] = face_oval_landmark_array.mean(axis=0)\n",
    "\n",
    "\n",
    "            ver_mean_diff = torch.mean(face_landmark_array[OVAL_LOWER_HALF], axis=0) - torch.mean(face_landmark_array[OVAL_UPPER_HALF], axis=0)\n",
    "            hor_mean_diff = torch.mean(face_landmark_array[OVAL_RIGHT_HALF], axis=0) - torch.mean(face_landmark_array[OVAL_LEFT_HALF],  axis=0)\n",
    "            normal_vec = torch.cross(hor_mean_diff, ver_mean_diff)\n",
    "            data[\"normal_vec\"] = torch.Tensor([\n",
    "                [0, 0, 0],\n",
    "                normal_vec.numpy()\n",
    "            ]) + torch.mean(face_oval_landmark_array, axis=0)\n",
    "\n",
    "            landmark_array = np.array(label_data[\"face_landmark_array\"])\n",
    "            ver_mean_diff = np.mean(landmark_array[OVAL_LOWER_HALF], axis=0) - np.mean(landmark_array[OVAL_UPPER_HALF], axis=0)\n",
    "            hor_mean_diff = np.mean(landmark_array[OVAL_RIGHT_HALF], axis=0) - np.mean(landmark_array[OVAL_LEFT_HALF],  axis=0)\n",
    "            normal_vec = np.cross(hor_mean_diff, ver_mean_diff)\n",
    "            normal_vec = np.array([ [0, 0, 0], normal_vec ]) + face_oval_landmark_array.numpy().mean(axis=0)\n",
    "            \n",
    "            print(data[\"normal_vec\"])\n",
    "            print(normal_vec)\n",
    "\n",
    "\n",
    "        if self.return_image :\n",
    "            image = Image.open(self.image_path_list[index])\n",
    "            left_eye_lt_rb = np.array([\n",
    "                left_eye_landmark_array.numpy().min(axis=0),\n",
    "                left_eye_landmark_array.numpy().max(axis=0),\n",
    "            ])[:, :2] * np.array([image.width, image.height])\n",
    "            #left_eye_lt_rb = left_eye_lt_rb * 2 - left_eye_lt_rb.mean(axis=0)\n",
    "            left_eye_lt_rb = left_eye_lt_rb.flatten().astype(int)\n",
    "\n",
    "            right_eye_lt_rb = np.array([\n",
    "                right_eye_landmark_array.numpy().min(axis=0),\n",
    "                right_eye_landmark_array.numpy().max(axis=0),\n",
    "            ])[:, :2] * np.array([image.width, image.height])\n",
    "            #right_eye_lt_rb = right_eye_lt_rb * 2 - right_eye_lt_rb.mean(axis=0)\n",
    "            right_eye_lt_rb = right_eye_lt_rb.flatten().astype(int)\n",
    "\n",
    "            left_eye_image  = self.to_torch(image.crop(left_eye_lt_rb))\n",
    "            right_eye_image = self.to_torch(image.crop(right_eye_lt_rb))\n",
    "            \n",
    "            data[\"image\"] =  self.to_torch(image)\n",
    "            data[\"left_eye_image\"] =  left_eye_image\n",
    "            data[\"right_eye_image\"] =  right_eye_image\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9513\n",
      "tensor([[0.5209, 0.7386, 0.0452],\n",
      "        [0.5212, 0.7356, 0.0208]])\n",
      "[[0.52088994 0.73859817 0.04519788]\n",
      " [0.52115936 0.73562229 0.02079852]]\n",
      "tensor([[0.5209, 0.7386, 0.0452],\n",
      "        [0.5212, 0.7356, 0.0208]])\n",
      "tensor([0.5209, 0.7386, 0.0452])\n"
     ]
    }
   ],
   "source": [
    "eye_tracker_dataset = EyeTrackerDataset(DATA_ROOT_PATH)\n",
    "\n",
    "print(len(eye_tracker_dataset))\n",
    "\n",
    "\n",
    "data = eye_tracker_dataset[1600]\n",
    "\n",
    "print(data[\"normal_vec\"])\n",
    "\n",
    "\n",
    "print(data[\"face_oval_mean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "objc[18941]: Class CaptureDelegate is implemented in both /opt/anaconda3/envs/first/lib/python3.10/site-packages/mediapipe/.dylibs/libopencv_videoio.3.4.16.dylib (0x1041cc860) and /opt/anaconda3/envs/first/lib/python3.10/site-packages/cv2/cv2.abi3.so (0x169d065a0). One of the two will be used. Which one is undefined.\n",
      "objc[18941]: Class CVWindow is implemented in both /opt/anaconda3/envs/first/lib/python3.10/site-packages/mediapipe/.dylibs/libopencv_highgui.3.4.16.dylib (0x102c3ca68) and /opt/anaconda3/envs/first/lib/python3.10/site-packages/cv2/cv2.abi3.so (0x169d065f0). One of the two will be used. Which one is undefined.\n",
      "objc[18941]: Class CVView is implemented in both /opt/anaconda3/envs/first/lib/python3.10/site-packages/mediapipe/.dylibs/libopencv_highgui.3.4.16.dylib (0x102c3ca90) and /opt/anaconda3/envs/first/lib/python3.10/site-packages/cv2/cv2.abi3.so (0x169d06618). One of the two will be used. Which one is undefined.\n",
      "objc[18941]: Class CVSlider is implemented in both /opt/anaconda3/envs/first/lib/python3.10/site-packages/mediapipe/.dylibs/libopencv_highgui.3.4.16.dylib (0x102c3cab8) and /opt/anaconda3/envs/first/lib/python3.10/site-packages/cv2/cv2.abi3.so (0x169d06640). One of the two will be used. Which one is undefined.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 57\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m     54\u001b[0m     \u001b[39mreturn\u001b[39;00m tesel\n\u001b[0;32m---> 57\u001b[0m FACE_TESSELATION_PATH_LIST \u001b[39m=\u001b[39m edge_list_2_path(np\u001b[39m.\u001b[39marray(\u001b[39mlist\u001b[39m(\n\u001b[1;32m     58\u001b[0m     mp_face_mesh\u001b[39m.\u001b[39mFACEMESH_TESSELATION\n\u001b[1;32m     59\u001b[0m ))\u001b[39m.\u001b[39mtolist())\n\u001b[1;32m     60\u001b[0m FACE_OVAL_PATH_LIST \u001b[39m=\u001b[39m edge_list_2_path(np\u001b[39m.\u001b[39marray(\u001b[39mlist\u001b[39m(\n\u001b[1;32m     61\u001b[0m     mp_face_mesh\u001b[39m.\u001b[39mFACEMESH_FACE_OVAL\n\u001b[1;32m     62\u001b[0m ))\u001b[39m.\u001b[39mtolist())\n\u001b[1;32m     63\u001b[0m FACE_LIPS_PATH_LIST \u001b[39m=\u001b[39m edge_list_2_path(np\u001b[39m.\u001b[39marray(\u001b[39mlist\u001b[39m(\n\u001b[1;32m     64\u001b[0m     mp_face_mesh\u001b[39m.\u001b[39mFACEMESH_LIPS\n\u001b[1;32m     65\u001b[0m ))\u001b[39m.\u001b[39mtolist())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "def edge_list_2_path(edge_list) :\n",
    "    tesel = edge_list\n",
    "    change_occured = True\n",
    "    while change_occured :\n",
    "        change_occured = False\n",
    "        for idx in range(len(tesel)) :\n",
    "            target_edge = tesel[idx]\n",
    "            inner_changed = False\n",
    "            for e in tesel :\n",
    "                if e != target_edge and len(e) < 3 :\n",
    "                    edge = e\n",
    "                    if target_edge[-1] == edge[0] :\n",
    "                        target_edge.append(edge[-1])\n",
    "                        tesel.remove(edge)\n",
    "                        change_occured = True\n",
    "                        inner_changed = True\n",
    "                        break\n",
    "                    if target_edge[0] == edge[-1] :\n",
    "                        target_edge.insert(0, edge[0])\n",
    "                        tesel.remove(edge)\n",
    "                        change_occured = True\n",
    "                        inner_changed  = True\n",
    "                        break\n",
    "            if inner_changed :\n",
    "                break\n",
    "    change_occured = True\n",
    "    while change_occured :\n",
    "        change_occured = False\n",
    "        for idx in range(len(tesel)) :\n",
    "            source_path = tesel[idx]\n",
    "            inner_changed = False\n",
    "            for target_path in tesel :\n",
    "                if target_path == source_path :\n",
    "                    continue\n",
    "                if source_path[-1] == target_path[-1] :\n",
    "                    target_path.reverse()\n",
    "                    source_path += target_path[1:]\n",
    "                    tesel.remove(target_path)\n",
    "                    change_occured = True\n",
    "                    inner_changed = True\n",
    "                    break\n",
    "                if source_path[0] == target_path[0] :\n",
    "                    source_path.reverse()\n",
    "                    target_path += source_path[1:]\n",
    "                    tesel.remove(source_path)\n",
    "                    change_occured = True\n",
    "                    inner_changed = True\n",
    "                    break\n",
    "            if inner_changed :\n",
    "                break\n",
    "    return tesel\n",
    "\n",
    "\n",
    "FACE_TESSELATION_PATH_LIST = edge_list_2_path(np.array(list(\n",
    "    mp_face_mesh.FACEMESH_TESSELATION\n",
    ")).tolist())\n",
    "FACE_OVAL_PATH_LIST = edge_list_2_path(np.array(list(\n",
    "    mp_face_mesh.FACEMESH_FACE_OVAL\n",
    ")).tolist())\n",
    "FACE_LIPS_PATH_LIST = edge_list_2_path(np.array(list(\n",
    "    mp_face_mesh.FACEMESH_LIPS\n",
    ")).tolist())\n",
    "FACE_LEFT_EYEBROW_PATH_LIST = edge_list_2_path(np.array(list(\n",
    "    mp_face_mesh.FACEMESH_LEFT_EYEBROW\n",
    ")).tolist())\n",
    "FACE_LEFT_EYE_PATH_LIST = edge_list_2_path(np.array(list(\n",
    "    mp_face_mesh.FACEMESH_LEFT_EYE\n",
    ")).tolist())\n",
    "FACE_LEFT_IRIS_PATH_LIST = edge_list_2_path(np.array(list(\n",
    "    mp_face_mesh.FACEMESH_LEFT_IRIS\n",
    ")).tolist())\n",
    "FACE_RIGHT_EYEBROW_PATH_LIST = edge_list_2_path(np.array(list(\n",
    "    mp_face_mesh.FACEMESH_RIGHT_EYEBROW\n",
    ")).tolist())\n",
    "FACE_RIGHT_EYE_PATH_LIST = edge_list_2_path(np.array(list(\n",
    "    mp_face_mesh.FACEMESH_RIGHT_EYE\n",
    ")).tolist())\n",
    "FACE_RIGHT_IRIS_PATH_LIST = edge_list_2_path(np.array(list(\n",
    "    mp_face_mesh.FACEMESH_RIGHT_IRIS\n",
    ")).tolist())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[263, 249, 390, 373, 374, 380, 381, 382, 362, 398, 384, 385, 386, 387, 388, 466, 263]\n",
      "\n",
      "[475, 476, 477, 474, 475]\n",
      "\n",
      "[33, 7, 163, 144, 145, 153, 154, 155, 133, 173, 157, 158, 159, 160, 161, 246, 33]\n",
      "\n",
      "[471, 472, 469, 470, 471]\n"
     ]
    }
   ],
   "source": [
    "print(FACE_LEFT_EYE_PATH_LIST[0])\n",
    "print()\n",
    "print(FACE_LEFT_IRIS_PATH_LIST[0])\n",
    "print()\n",
    "print(FACE_RIGHT_EYE_PATH_LIST[0])\n",
    "print()\n",
    "print(FACE_RIGHT_IRIS_PATH_LIST[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0471975511965976"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arccos( 1 / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "first",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
