{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "DATA_ROOT_PATH = \"../eye_tracker_auto_labeller/data\"\n",
    "\n",
    "FACE_OVAL_LANDMARK_IDX_LIST = [\n",
    "    162,  21,  54, 103,  67, 109,  10, 338, 297, 332, 284, 251, 389,\n",
    "    356, 454, 323, 361, 288, 397, 365, 379, 378, 400, 377, 152, 148,\n",
    "    176, 149, 150, 136, 172,  58, 132,  93, 234, 127, 162,\n",
    "]\n",
    "LEFT_EYE_LANDMARK_IDX_LIST = [\n",
    "    263, 249, 390, 373, 374, 380, 381, 382, 362, \n",
    "    398, 384, 385, 386, 387, 388, 466, 263\n",
    "]\n",
    "LEFT_IRIS_LANDMARK_IDX_LIST = [475, 476, 477, 474, 475]\n",
    "RIGHT_EYE_LANDMARK_IDX_LIST = [\n",
    "     33,   7, 163, 144, 145, 153, 154, 155, 133,\n",
    "    173, 157, 158, 159, 160, 161, 246, 33\n",
    "]\n",
    "RIGHT_IRIS_LANDMARK_IDX_LIST = [471, 472, 469, 470, 471]\n",
    "\n",
    "OVAL_UPPER_HALF = [361, 288, 397, 365, 379, 378, 400, 377, 152, 148, 176, 149, 150, 136, 172,  58, 132]\n",
    "OVAL_LOWER_HALF = [234, 127, 162,  21,  54, 103,  67, 109,  10, 338, 297, 332, 284, 251, 389, 356, 454]\n",
    "OVAL_LEFT_HALF  = [338, 297, 332, 284, 251, 389, 356, 454, 323, 361, 288, 397, 365, 379, 378, 400, 377]\n",
    "OVAL_RIGHT_HALF = [148, 176, 149, 150, 136, 172,  58, 132,  93, 234, 127, 162,  21,  54, 103,  67, 109]\n",
    "\n",
    "class EyeTrackerDataset(Dataset) :\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_root_path = DATA_ROOT_PATH,\n",
    "        face_oval_landmark_idx_list     = FACE_OVAL_LANDMARK_IDX_LIST,\n",
    "        left_eye_landmark_idx_list      = LEFT_EYE_LANDMARK_IDX_LIST,\n",
    "        left_iris_landmark_idx_list     = LEFT_IRIS_LANDMARK_IDX_LIST,\n",
    "        right_eye_landmark_idx_list     = RIGHT_EYE_LANDMARK_IDX_LIST,\n",
    "        right_iris_landmark_idx_list    = RIGHT_IRIS_LANDMARK_IDX_LIST,\n",
    "        return_landmark = True,\n",
    "        return_image = False\n",
    "    ) :\n",
    "        super(EyeTrackerDataset, self).__init__()\n",
    "        self.DATA_ROOT_PATH = data_root_path\n",
    "        self.face_oval_landmark_idx_list    = face_oval_landmark_idx_list\n",
    "        self.left_eye_landmark_idx_list     = left_eye_landmark_idx_list\n",
    "        self.left_iris_landmark_idx_list    = left_iris_landmark_idx_list\n",
    "        self.right_eye_landmark_idx_list    = right_eye_landmark_idx_list\n",
    "        self.right_iris_landmark_idx_list   = right_iris_landmark_idx_list\n",
    "        self.return_landmark = return_landmark\n",
    "        self.return_image = return_image\n",
    "\n",
    "        self.label_path_list = sorted(glob(\n",
    "            f\"{self.DATA_ROOT_PATH}/*/*.json\"\n",
    "        ))\n",
    "        self.image_path_list = sorted(glob(\n",
    "            f\"{self.DATA_ROOT_PATH}/*/*.png\"\n",
    "        ))\n",
    "\n",
    "        # there might exists case where eiter image or label does not exist\n",
    "        # ex) a.json exist but a.png doesn't exist or vice-versa.\n",
    "        # filter this cases to ensure every data are image-label pair.\n",
    "        self.label_path_list = list(filter(\n",
    "            lambda file_name : file_name.replace(\"json\", \"png\") in self.image_path_list,\n",
    "            self.label_path_list\n",
    "        ))\n",
    "        self.image_path_list = list(filter(\n",
    "            lambda file_name : file_name.replace(\"png\", \"json\") in self.label_path_list,\n",
    "            self.image_path_list\n",
    "        ))\n",
    "        assert len(self.label_path_list) == len(self.image_path_list)\n",
    "\n",
    "        self.to_torch = transforms.ToTensor()\n",
    "\n",
    "    def __len__(self) :\n",
    "        return len(self.label_path_list)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        with open(self.label_path_list[index], \"r\") as fp :\n",
    "            label_data = json.load(fp)\n",
    "        mouse_position = torch.Tensor(label_data[\"mouse_position\"])\n",
    "        data = {\n",
    "            \"mouse_position\" : mouse_position\n",
    "        }\n",
    "        if self.return_landmark :\n",
    "            face_landmark_array = torch.Tensor(label_data[\"face_landmark_array\"])\n",
    "            face_oval_landmark_array  = face_landmark_array[self.face_oval_landmark_idx_list]\n",
    "            left_eye_landmark_array   = face_landmark_array[self.left_eye_landmark_idx_list]\n",
    "            right_eye_landmark_array  = face_landmark_array[self.right_eye_landmark_idx_list]\n",
    "            left_iris_landmark_array  = face_landmark_array[self.left_iris_landmark_idx_list]\n",
    "            right_iris_landmark_array = face_landmark_array[self.right_iris_landmark_idx_list]\n",
    "\n",
    "            data[\"face_landmark_array\"] = face_landmark_array\n",
    "            data[\"face_oval_landmark_array\"] = face_oval_landmark_array\n",
    "            data[\"left_eye_landmark_array\"] = left_eye_landmark_array\n",
    "            data[\"right_eye_landmark_array\"] = right_eye_landmark_array\n",
    "            data[\"left_iris_landmark_array\"] = left_iris_landmark_array\n",
    "            data[\"right_iris_landmark_array\"] = right_iris_landmark_array\n",
    "            data[\"face_oval_mean\"] = face_oval_landmark_array.mean(axis=0)\n",
    "\n",
    "            eye_center_pos = face_landmark_array[LEFT_EYE_LANDMARK_IDX_LIST[0] + RIGHT_EYE_LANDMARK_IDX_LIST[0]].mean(axis=0)\n",
    "            data[\"eye_center_pos\"] = eye_center_pos\n",
    "            \n",
    "            face_dir_x = torch.mean(face_landmark_array[OVAL_RIGHT_HALF], axis=0) - torch.mean(face_landmark_array[OVAL_LEFT_HALF],  axis=0)\n",
    "            face_dir_y = torch.mean(face_landmark_array[OVAL_LOWER_HALF], axis=0) - torch.mean(face_landmark_array[OVAL_UPPER_HALF], axis=0)\n",
    "            face_dir_z = torch.cross(face_dir_x, face_dir_y)\n",
    "            face_area_factor = torch.sqrt(torch.sqrt(torch.sum(torch.square(face_dir_z))))\n",
    "            data[\"face_area_factor\"] = face_area_factor\n",
    "\n",
    "            face_dir_x_norm = face_dir_x / torch.sqrt(torch.sum(face_dir_x * face_dir_x))\n",
    "            face_dir_y_norm = face_dir_y / torch.sqrt(torch.sum(face_dir_y * face_dir_y))\n",
    "            face_dir_z_norm = face_dir_z / torch.sqrt(torch.sum(face_dir_z * face_dir_z))\n",
    "            data[\"face_dir_x_norm\"] = face_dir_x_norm\n",
    "            data[\"face_dir_y_norm\"] = face_dir_y_norm\n",
    "            data[\"face_dir_z_norm\"] = face_dir_z_norm\n",
    "\n",
    "            pitch = torch.arctan2(-face_dir_z_norm[1], -face_dir_z_norm[2])\n",
    "            yaw   = torch.arcsin(face_dir_z_norm[0])\n",
    "            roll  = torch.arctan2(-face_dir_y_norm[0], face_dir_x_norm[0])\n",
    "            data[\"roll\"]  = roll\n",
    "            data[\"pitch\"] = pitch\n",
    "            data[\"yaw\"]   = yaw\n",
    "\n",
    "        if self.return_image :\n",
    "            image = Image.open(self.image_path_list[index])\n",
    "            left_eye_lt_rb = np.array([\n",
    "                left_eye_landmark_array.numpy().min(axis=0),\n",
    "                left_eye_landmark_array.numpy().max(axis=0),\n",
    "            ])[:, :2] * np.array([image.width, image.height])\n",
    "            #left_eye_lt_rb = left_eye_lt_rb * 2 - left_eye_lt_rb.mean(axis=0)\n",
    "            left_eye_lt_rb = left_eye_lt_rb.flatten().astype(int)\n",
    "\n",
    "            right_eye_lt_rb = np.array([\n",
    "                right_eye_landmark_array.numpy().min(axis=0),\n",
    "                right_eye_landmark_array.numpy().max(axis=0),\n",
    "            ])[:, :2] * np.array([image.width, image.height])\n",
    "            #right_eye_lt_rb = right_eye_lt_rb * 2 - right_eye_lt_rb.mean(axis=0)\n",
    "            right_eye_lt_rb = right_eye_lt_rb.flatten().astype(int)\n",
    "\n",
    "            left_eye_image  = self.to_torch(image.crop(left_eye_lt_rb))\n",
    "            right_eye_image = self.to_torch(image.crop(right_eye_lt_rb))\n",
    "            \n",
    "            data[\"image\"] =  self.to_torch(image)\n",
    "            data[\"left_eye_image\"] =  left_eye_image\n",
    "            data[\"right_eye_image\"] =  right_eye_image\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mouse_position', 'face_landmark_array', 'face_oval_landmark_array', 'left_eye_landmark_array', 'right_eye_landmark_array', 'left_iris_landmark_array', 'right_iris_landmark_array', 'face_oval_mean', 'eye_center_pos', 'face_area_factor', 'face_dir_x_norm', 'face_dir_y_norm', 'face_dir_z_norm', 'roll', 'pitch', 'yaw', 'image', 'left_eye_image', 'right_eye_image'])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eye_tracker_dataset = EyeTrackerDataset(DATA_ROOT_PATH, return_image=True)\n",
    "\n",
    "data = eye_tracker_dataset[1600]\n",
    "\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(val, dim=3) :\n",
    "     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "first",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
